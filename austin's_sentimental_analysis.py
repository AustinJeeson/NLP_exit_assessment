# -*- coding: utf-8 -*-
"""Austin's Sentimental Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x_gqrU69lM1mu9NTpxt-cMopVh87q7NY
"""

import pandas as pd
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, f1_score

# Load the datasets
train_path = "/content/drive/MyDrive/Exit_Project/train_2kmZucJ.csv"
test_path = "/content/drive/MyDrive/Exit_Project/test_oJQbWVk.csv"
train_df = pd.read_csv(train_path)
test_df = pd.read_csv(test_path)

# Inspect label distribution
print("Label Distribution:\n", train_df['label'].value_counts())

# Text cleaning function
def clean_text(text):
    text = re.sub(r"http\S+", "", text)          # Remove URLs
    text = re.sub(r"#\S+", "", text)             # Remove hashtags
    text = re.sub(r"@\S+", "", text)             # Remove mentions
    text = re.sub(r"[^A-Za-z0-9\s]", "", text)   # Remove special characters
    text = text.lower().strip()                  # Lowercase and strip
    return text

# Clean tweets
train_df["clean_tweet"] = train_df["tweet"].apply(clean_text)
test_df["clean_tweet"] = test_df["tweet"].apply(clean_text)

# Split data for validation
X = train_df["clean_tweet"]
y = train_df["label"]
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Improved pipeline with class_weight and tuned vectorizer
model = Pipeline([
    ('tfidf', TfidfVectorizer(max_features=7000, ngram_range=(1,2))),
    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', C=1.0))
])

# Train the model
model.fit(X_train, y_train)

# Validation predictions
val_preds = model.predict(X_val)

# Evaluate
print("üìä Validation Performance:")
print("Accuracy:", accuracy_score(y_val, val_preds))
print("F1 Score:", f1_score(y_val, val_preds))
print("Classification Report (1 = negative , 0 = non-negative):\n", classification_report(y_val, val_preds))

# Predict on test set
test_preds = model.predict(test_df["clean_tweet"])
test_df["label"] = test_preds

# Save predictions
test_df[['id', 'label']].to_csv("test_predictions_fixed.csv", index=False)

# Show a few predictions
print("\nüîç Sample Predictions:")
print(test_df[['id', 'tweet', 'label']])

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Assuming y_val and val_preds are already defined
cm = confusion_matrix(y_val, val_preds, labels=[0, 1])
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Negative", "Positive"])

plt.figure(figsize=(6, 5))
disp.plot(cmap="Blues", values_format='d')
plt.title("Confusion Matrix - Validation Set")
plt.grid(False)
plt.show()

from google.colab import files
files.download('test_predictions_fixed.csv')